{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quora Question Similarity-2 .ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mitesh98/Quora_Question_Pair_Similarity/blob/master/Quora_Question_Similarity_2_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nM_T3-bb57wg",
        "colab_type": "text"
      },
      "source": [
        "**1.2.1 : EDA: Advanced Feature Extraction.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtiDuDveudWT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c645ea1d-f87b-40af-fbfa-0aa0793b3753"
      },
      "source": [
        "!pip install fuzzywuzzy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading https://files.pythonhosted.org/packages/d8/f1/5a267addb30ab7eaa1beab2b9323073815da4551076554ecc890a3595ec9/fuzzywuzzy-0.17.0-py2.py3-none-any.whl\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.17.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZAFCYbtmlUo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f8b2b41e-3731-4ccc-8897-60224a9e34e6"
      },
      "source": [
        "!pip install distance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting distance\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/1a/883e47df323437aefa0d0a92ccfb38895d9416bd0b56262c2e46a47767b8/Distance-0.1.3.tar.gz (180kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 17.3MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 40kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 51kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 102kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 112kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 122kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 133kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 143kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 153kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 163kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 174kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 2.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: distance\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-cp36-none-any.whl size=16261 sha256=8213ab6243ec99d7125905539929a2741f9a582860da8d4fd5e3360a9b55d0d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/aa/e1/dbba9e7b6d397d645d0f12db1c66dbae9c5442b39b001db18e\n",
            "Successfully built distance\n",
            "Installing collected packages: distance\n",
            "Successfully installed distance-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6s9uNVXU5qzQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "42566d89-3be2-4e4e-f57a-f5829e08057d"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from subprocess import check_output\n",
        "%matplotlib inline\n",
        "import plotly.offline as py\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go\n",
        "import plotly.tools as tls\n",
        "import os\n",
        "import gc\n",
        "\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "# This package is used for finding longest common subsequence between two strings\n",
        "import distance\n",
        "# you can write your own dp code for this\n",
        "from nltk.stem import PorterStemmer\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.manifold import TSNE\n",
        "# Import the Required lib packages for WORD-Cloud generation\n",
        "# https://stackoverflow.com/questions/45625434/how-to-install-wordcloud-in-python3-6\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from os import path\n",
        "from PIL import Image\n",
        "from fuzzywuzzy import fuzz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z60zsWXE95yY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f11241b0-2b30-4da5-d30d-e7f010f7402e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YD5Ahu8-9E8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/drive/My Drive/Colab Notebooks/train2.csv' 'train2.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MThFpkunAwsM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "896c20e6-8b42-4202-c4b8-12241147f1ca"
      },
      "source": [
        "data=pd.read_csv('train2.csv')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "      <th>freq_qid1</th>\n",
              "      <th>freq_qid2</th>\n",
              "      <th>q1len</th>\n",
              "      <th>q2len</th>\n",
              "      <th>q1_n_words</th>\n",
              "      <th>q2_n_words</th>\n",
              "      <th>word_Common</th>\n",
              "      <th>word_Total</th>\n",
              "      <th>word_Share</th>\n",
              "      <th>freq_q1+q2</th>\n",
              "      <th>freq_q1-q2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>66</td>\n",
              "      <td>57</td>\n",
              "      <td>14</td>\n",
              "      <td>12</td>\n",
              "      <td>10.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>88</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>4.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>73</td>\n",
              "      <td>59</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>4.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>65</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>76</td>\n",
              "      <td>39</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  qid2  ... word_Share freq_q1+q2  freq_q1-q2\n",
              "0   0     1     2  ...   0.434783          2           0\n",
              "1   1     3     4  ...   0.200000          5           3\n",
              "2   2     5     6  ...   0.166667          2           0\n",
              "3   3     7     8  ...   0.000000          2           0\n",
              "4   4     9    10  ...   0.100000          4           2\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D2UvNLkKKDl",
        "colab_type": "text"
      },
      "source": [
        "**3.4 Preprocessing of Text**\n",
        "\n",
        "* Preprocessing:\n",
        "\n",
        "* Removing html tags\n",
        "\n",
        "* Removing Punctuations\n",
        "\n",
        "* Performing stemming\n",
        "\n",
        "* Removing Stopwords\n",
        "\n",
        "* Expanding contractions etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti-bcK4eKZNK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f238f2b3-030d-4231-a332-567957db0189"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "Stopwords=stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OzkUsYZgp8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Preprocessing(x):\n",
        "  x=x.replace(\",000,000\",'m').replace(\",000\",'k').replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
        "               .replace(\"won't\", \"will not\").replace(\"cannot\", \"can not\").replace(\"can't\", \"can not\")\\\n",
        "                           .replace(\"n't\", \" not\").replace(\"what's\", \"what is\").replace(\"it's\", \"it is\")\\\n",
        "                           .replace(\"'ve\", \" have\").replace(\"i'm\", \"i am\").replace(\"'re\", \" are\")\\\n",
        "                           .replace(\"he's\", \"he is\").replace(\"she's\", \"she is\").replace(\"'s\", \" own\")\\\n",
        "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
        "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\")\n",
        "  x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
        "  x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
        "  porter = PorterStemmer()\n",
        "  pattern = re.compile('\\W')\n",
        "    \n",
        "  if type(x) == type(''):\n",
        "    x = re.sub(pattern, ' ', x)\n",
        "    \n",
        "    \n",
        "  if type(x) == type(''):\n",
        "    x = porter.stem(x)\n",
        "    example1 = BeautifulSoup(x)\n",
        "    x = example1.get_text()\n",
        "               \n",
        "    \n",
        "  return x\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC3Ubrqpb8ww",
        "colab_type": "text"
      },
      "source": [
        "* Function to Compute and get the features : With 2 parameters of Question 1 and Question 2\n",
        "\n",
        "## 3.5 Advanced Feature Extraction (NLP and Fuzzy Features)\n",
        "\n",
        "Definition:\n",
        "\n",
        "* **Token**: You get a token by splitting sentence a space\n",
        "\n",
        "* **Stop_Word** : stop words as per NLTK.\n",
        "\n",
        "* **Word**  : A token that is not a stop_word\n",
        "\n",
        "Features:\n",
        "\n",
        "* **cwc_min** : Ratio of common_word_count to min lenghth of word count of Q1 and Q2 \n",
        "\n",
        "* **cwc_min** = common_word_count / (min(len(q1_words), len(q2_words)) \n",
        "\n",
        "* **cwc_max** : Ratio of common_word_count to max lenghth of word count of Q1 and Q2 \n",
        "\n",
        "* **cwc_max** = common_word_count / (max(len(q1_words), len(q2_words)) \n",
        "\n",
        "* **csc_min** : Ratio of common_stop_count to min lenghth of stop count of Q1 and Q2 \n",
        "\n",
        "* **csc_min** = common_stop_count / (min(len(q1_stops), len(q2_stops)) \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D618etI_duKn",
        "colab_type": "text"
      },
      "source": [
        "* **csc_max** : Ratio of common_stop_count to max lenghth of stop count of Q1 and Q2\n",
        "\n",
        "* **csc_max** = common_stop_count / (max(len(q1_stops), len(q2_stops)) \n",
        "\n",
        "* **ctc_min** : Ratio of common_token_count to min lenghth of token count of Q1 and Q2\n",
        "\n",
        "* **ctc_min** = common_token_count / (min(len(q1_tokens), len(q2_tokens)) \n",
        "\n",
        "\n",
        "* **ctc_max** : Ratio of common_token_count to max lenghth of token count of Q1 and Q2\n",
        "\n",
        "* **ctc_max** = common_token_count / (max(len(q1_tokens), len(q2_tokens)) \n",
        "\n",
        "\n",
        "* **last_word_eq**  : Check if First word of both questions is equal or not\n",
        "\n",
        "* **last_word_eq** = int(q1_tokens[-1] == q2_tokens[-1]) \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NckSVGEzeT9C",
        "colab_type": "text"
      },
      "source": [
        "* **first_word_eq** : Check if First word of both questions is equal or not\n",
        "\n",
        "* **first_word_eq** = int(q1_tokens[0] == q2_tokens[0]) \n",
        "\n",
        "\n",
        "* **abs_len_diff** : Abs. length difference\n",
        "\n",
        "* **abs_len_diff** = abs(len(q1_tokens) - len(q2_tokens)) \n",
        "\n",
        "\n",
        "* **mean_len** : Average Token Length of both Questions\n",
        "\n",
        "* **mean_len** = (len(q1_tokens) + len(q2_tokens))/2 \n",
        "\n",
        "\n",
        "* **fuzz_ratio** : https://github.com/seatgeek/fuzzywuzzy#usage http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/ \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx4dAgt5uqJ6",
        "colab_type": "text"
      },
      "source": [
        "* **fuzz_partial_ratio** : https://github.com/seatgeek/fuzzywuzzy#usage http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/ \n",
        "\n",
        "\n",
        "* **token_sort_ratio** : https://github.com/seatgeek/fuzzywuzzy#usage http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/ \n",
        "\n",
        "* **token_set_ratio** : https://github.com/seatgeek/fuzzywuzzy#usage http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/ \n",
        "\n",
        "* **longest_substr_ratio** : Ratio of length longest common substring to min lenghth of token count of Q1 and Q2\n",
        "longest_substr_ratio = len(longest common substring) / (min(len(q1_tokens), len(q2_tokens))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUSadqWku4Gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SAFE_DIV=0.0001\n",
        "def get_tokens_feature(q1,q2):\n",
        "  \n",
        "  token_features=[0.0]*10\n",
        "  \n",
        "  #Token \n",
        "  q1_tokens=q1.split()\n",
        "  q2_tokens=q2.split()\n",
        "  \n",
        "  #return if  \n",
        "  if len(q1_tokens)==0 or len(q2_tokens)==0:\n",
        "    return token_features\n",
        "  \n",
        "  #Words\n",
        "  q1_words = set(word for word in q1_tokens if word not in Stopwords )\n",
        "  q2_words = set(word for word in q2_tokens if word not in Stopwords )\n",
        "  \n",
        "  # Stop Words in Question\n",
        "  q1_stopwords = set(word for word in q1_tokens if word in Stopwords )\n",
        "  q2_stopwords = set(word for word in q2_tokens if word in Stopwords )\n",
        "  \n",
        "  # Counting common words in Question pair\n",
        "  common_word_count =len(q1_words.intersection(q2_words))\n",
        "  \n",
        "  #Counting common Stopwords in Question pair\n",
        "  common_stopwords_count =len(q1_stopwords.intersection(q2_stopwords))\n",
        "  \n",
        "  # Get the common words in Question pair\n",
        "  common_token_count =len(set(q1_tokens).intersection(q2_tokens))\n",
        "  \n",
        "  #Common_Word_Count_Min\n",
        "  token_features[0]= common_word_count/(min(len(q1_words),len(q2_words))+SAFE_DIV)\n",
        "  \n",
        "  #Common_Word_Count_Max\n",
        "  token_features[1]= common_word_count/(max(len(q1_words),len(q2_words))+SAFE_DIV)\n",
        "  \n",
        "  #Common_StopWord_Count_Min\n",
        "  token_features[2]= common_stopwords_count/(min(len(q1_stopwords),len(q2_stopwords))+SAFE_DIV)\n",
        "  \n",
        "  #Common_StopWord_Count_Max\n",
        "  token_features[3]= common_stopwords_count/(max(len(q1_stopwords),len(q2_stopwords))+SAFE_DIV)\n",
        "  \n",
        "  #Common_StopWord_Count_Min\n",
        "  token_features[4]= common_token_count/(min(len(q1_tokens),len(q2_tokens))+SAFE_DIV)\n",
        "  \n",
        "  #Common_StopWord_Count_Max\n",
        "  token_features[5]= common_token_count/(max(len(q1_tokens),len(q2_tokens))+SAFE_DIV)\n",
        "  \n",
        "  # Last word of both question is same or not\n",
        "  token_features[6]= int(q1_tokens[-1]==q2_tokens[-1])\n",
        "  \n",
        "  # First word of both question is same or not\n",
        "  token_features[7]= int(q1_tokens[0]==q2_tokens[0])\n",
        "  \n",
        "  #Absolute_Token_length_difference \n",
        "  token_features[8]=abs(len(q1_tokens)-len(q2_tokens))\n",
        "  \n",
        "  #Average_Token_length_\n",
        "  token_features[9]=(len(q1_tokens)+len(q2_tokens))/2\n",
        "  \n",
        "  return token_features\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keNcHOdL34Wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Longest Common substring using ditance library using lcsubstrings function\n",
        "def get_longest_substr_ratio(a,b):\n",
        "  substring=list(distance.lcsubstrings(a,b))\n",
        "  if len(substring)==0:\n",
        "    return 0\n",
        "  else:\n",
        "    return len(substring[0])/min(len(a),len(b)+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PEcchX0pW2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(df):\n",
        "  print(\"Preprocessing...\")\n",
        "  #Preprocessing each question\n",
        "  df[\"question1\"]=df[\"question1\"].fillna(\"\").apply(Preprocessing)\n",
        "  df[\"question2\"]=df[\"question2\"].fillna(\"\").apply(Preprocessing)\n",
        "  \n",
        "  #Appending Advance Features\n",
        "  token_features=df.apply(lambda x:get_tokens_feature(x[\"question1\"],x[\"question2\"]),axis=1 ) \n",
        "  \n",
        "  #map(function_to_apply, list_of_inputs)\n",
        "  df[\"cwc_min\"]=       list(map(lambda x: x[0],token_features))\n",
        "  df[\"cwc_max\"]=       list(map(lambda x: x[1],token_features))\n",
        "  df[\"csc_min\"]=       list(map(lambda x: x[2],token_features))\n",
        "  df[\"csc_max\"]=       list(map(lambda x: x[3],token_features))\n",
        "  df[\"ctc_min\"]=       list(map(lambda x: x[4],token_features))\n",
        "  df[\"ctc_max\"]=       list(map(lambda x: x[5],token_features))\n",
        "  df[\"last_word_ed\"]=  list(map(lambda x: x[6],token_features))\n",
        "  df[\"first_word_ed\"]= list(map(lambda x: x[7],token_features))\n",
        "  df[\"abs_len_diff\"]=  list(map(lambda x: x[8],token_features))\n",
        "  df[\"mean_len\"]=      list(map(lambda x: x[9],token_features))\n",
        "\n",
        "  print(\"fuzzy features..\")\n",
        "  df[\"token_set_ratio\"]       = df.apply(lambda x: fuzz.token_set_ratio(x[\"question1\"],x[\"question2\"]),axis=1)\n",
        "  df[\"token_sort_ratio\"]      = df.apply(lambda x: fuzz.token_sort_ratio(x[\"question1\"],x[\"question2\"]),axis=1)\n",
        "  df[\"longest_substr_ratio\"]  = df.apply(lambda x:  get_longest_substr_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "  df[\"fuzz_partial_ratio\"]    = df.apply(lambda x: fuzz.partial_ratio(x[\"question1\"], x[\"question2\"]), axis=1)\n",
        "  \n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR6_-UyMzML7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "81c28b2b-3b5c-47fa-ea98-4c866c6d0c28"
      },
      "source": [
        "df = extract_features(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preprocessing...\n",
            "fuzzy features..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar-WEXE74aQR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "5f254f7a-8afc-4aef-8f8f-0beb2c7137d6"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "      <th>freq_qid1</th>\n",
              "      <th>freq_qid2</th>\n",
              "      <th>q1len</th>\n",
              "      <th>q2len</th>\n",
              "      <th>q1_n_words</th>\n",
              "      <th>q2_n_words</th>\n",
              "      <th>word_Common</th>\n",
              "      <th>word_Total</th>\n",
              "      <th>word_Share</th>\n",
              "      <th>freq_q1+q2</th>\n",
              "      <th>freq_q1-q2</th>\n",
              "      <th>cwc_min</th>\n",
              "      <th>cwc_max</th>\n",
              "      <th>csc_min</th>\n",
              "      <th>csc_max</th>\n",
              "      <th>ctc_min</th>\n",
              "      <th>ctc_max</th>\n",
              "      <th>last_word_ed</th>\n",
              "      <th>first_word_ed</th>\n",
              "      <th>abs_len_diff</th>\n",
              "      <th>mean_len</th>\n",
              "      <th>token_set_ratio</th>\n",
              "      <th>token_sort_ratio</th>\n",
              "      <th>longest_substr_ratio</th>\n",
              "      <th>fuzz_partial_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>what is the step by step guide to invest in sh...</td>\n",
              "      <td>what is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>66</td>\n",
              "      <td>57</td>\n",
              "      <td>14</td>\n",
              "      <td>12</td>\n",
              "      <td>10.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.434783</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.999980</td>\n",
              "      <td>0.833319</td>\n",
              "      <td>0.999983</td>\n",
              "      <td>0.999983</td>\n",
              "      <td>0.916659</td>\n",
              "      <td>0.785709</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>100</td>\n",
              "      <td>93</td>\n",
              "      <td>0.982759</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>what is the story of kohinoor  koh i noor  dia...</td>\n",
              "      <td>what would happen if the indian government sto...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>88</td>\n",
              "      <td>8</td>\n",
              "      <td>13</td>\n",
              "      <td>4.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0.799984</td>\n",
              "      <td>0.399996</td>\n",
              "      <td>0.749981</td>\n",
              "      <td>0.599988</td>\n",
              "      <td>0.699993</td>\n",
              "      <td>0.466664</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>12.5</td>\n",
              "      <td>86</td>\n",
              "      <td>63</td>\n",
              "      <td>0.607843</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>how can i increase the speed of my internet co...</td>\n",
              "      <td>how can internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>73</td>\n",
              "      <td>59</td>\n",
              "      <td>14</td>\n",
              "      <td>10</td>\n",
              "      <td>4.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.399992</td>\n",
              "      <td>0.333328</td>\n",
              "      <td>0.399992</td>\n",
              "      <td>0.249997</td>\n",
              "      <td>0.399996</td>\n",
              "      <td>0.285712</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>63</td>\n",
              "      <td>63</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>why am i mentally very lonely  how can i solve...</td>\n",
              "      <td>find the remainder when  math 23  24   math  i...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>65</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>28</td>\n",
              "      <td>24</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>which one dissolve in water quikly sugar  salt...</td>\n",
              "      <td>which fish would survive in salt water</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>76</td>\n",
              "      <td>39</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0.399992</td>\n",
              "      <td>0.199998</td>\n",
              "      <td>0.999950</td>\n",
              "      <td>0.666644</td>\n",
              "      <td>0.571420</td>\n",
              "      <td>0.307690</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>67</td>\n",
              "      <td>47</td>\n",
              "      <td>0.175000</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  qid1  qid2  ... token_sort_ratio longest_substr_ratio  fuzz_partial_ratio\n",
              "0   0     1     2  ...               93             0.982759                 100\n",
              "1   1     3     4  ...               63             0.607843                  75\n",
              "2   2     5     6  ...               63             0.166667                  47\n",
              "3   3     7     8  ...               24             0.040000                  14\n",
              "4   4     9    10  ...               47             0.175000                  56\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7socpI3zXaT",
        "colab_type": "text"
      },
      "source": [
        "**3.5.1 Analysis of extracted features**\n",
        "\n",
        "**3.5.1.1 Plotting Word clouds**\n",
        "\n",
        "* Creating Word Cloud of Duplicates and Non-Duplicates Question pairs\n",
        "\n",
        "* We can observe the most frequent occuring words"
      ]
    }
  ]
}